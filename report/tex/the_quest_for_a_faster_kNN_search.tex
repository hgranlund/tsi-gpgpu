%!TEX root = ./main.tex

\chapter{The quest for a faster kNN search} % (fold)
\label{sec:the_quest_for_a_faster_knn_search}

TechnoSoft Inc\@. is currently developing point cloud analysis software library. This software library is developed, with the goal of making comparisons between 3D models of a engineering design, and laser scans of the finished product. Such a comparison, would help engineers to pinpoint production errors faster, and more accurately.

In order to get good precision in the laser scan data, a large amount of points in 3D space has to be recorded. This set of data is commonly called a point cloud, and it can easily consist of $\numprint{1e6}$ to $\numprint{1e8}$ 3D points, or even more, as a larger number of recorded points give better accuracy in the data.

Processing such a large number of point, is a time consuming task, and reducing the time required for individual operations become important, since they will be repeated many times. Working on point cloud data is also a problem seemingly suitable for parallelization, since operations on individual points could be executed concurrently.

TSI has analyzed their current point cloud analysis algorithms, and determined that a lot of time is spent solving the All-kNN problem, for the point clouds. They would therefore try to improve performance by developing GPU parallelized algorithms, capable of solving the kNN and All-kNN problem for a high number of points, at least in the order of $\numprint{1e7}$ to $\numprint{1e8}$, and a low value for $k\le100$.

In this chapter, we will try to develop algorithms capable of solving the kNN and All-kNN problem, with the performance required by TSI\@.

\section{A short evaluation of OpenCL and CUDA} % (fold)
\label{sub:a_short_evaluation_of_opencl_and_cuda}

As mentioned in Section~\ref{ssub:general_purpose_computing_on_graphics_processing_units}, there are two dominant frameworks for GPGPU programming, CUDA and OpenCL\@. They both have their strengths and weaknesses, and in order to determine which was the most suitable for our work, we performed a small evaluation of both. This evaluation was based on a short benchmark test, where a matrix multiplication application was developed in both frameworks. The development time for both the CUDA and OpenCL matrix multiplier was limited, in order to highlight any differences in ease of use, between the two frameworks.

In addition, a quick analysis of available documentation for both frameworks was made, using common online search engines.

In all our tests CUDA outperformed OpenCL\@. Although our tests were very limited in scope, they support the opinion that currently, CUDA is faster and better documented than OpenCL\@. If the portability offered by OpenCL is not required, we would recommend using CUDA for GPGPU programming.

\subsection{Matrix multiplication benchmark} % (fold)
\label{sub:matrix_multiplication_benchmark}
In order to compare the performance differences between CUDA and OpenCL, a simple matrix multiplication algorithm was implemented in both CUDA and OpenCL\@. These implementations where based on examples provided by NVIDIA and AMD\@. In order to establish a baseline, to which the CUDA and OpenCL results could be compared, additional implementations of the matrix multiplication algorithm was made, as both a naive serial implementation in C and a highly optimized implementation using the Automatically Tuned Linear Algebra Software (ATLAS\cite{atlas}) implementation of BLAS\@. Finally, a highly optimized CUDA implementation was made using the cuBLAS\cite{cublas} library.

The test algorithm multiplies two square matrices of size NxN. This is an interesting problem to use for performance benchmarking for a number of reasons:

\begin{itemize}
    \item Matrix multiplication is often used as a subroutine in more advanced mathematical algorithms.
    \item Matrix multiplication can be parallelized over a large number of computational cores, making it suitable for GPGPU programming.
    \item The mathematics of matrix multiplication is trivial, making it an easy to understand example problem.
\end{itemize}

The four implementations where tested on test environments described in Table~\ref{tbl:test_envoronments}. The results are presented in Figure~\ref{fig:matrix-multiplication-benchmark-results}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=120mm]{../gfx/matrix-multiplication-benchmark-results.png}
    \caption{Matrix multiplication benchmark results}
    \label{fig:matrix-multiplication-benchmark-results}
\end{figure}

We see that the naive serial implementation quickly becomes unusable, due to a rapid increase in run time. The improvement gained by using ATLAS BLAS is very large compared to the naive implementation, although it cannot keep up with the run times achieved by the CUDA and OpenCL implementations.

The difference between CUDA and OpenCL is quite small, compared to the naive and BLAS implementations, but the CUDA implementation is on average about twice as fast as the OpenCL implementation. This is quite a big difference, and this could be related to all tests being run on a NVIDIA graphics card. It might also have been caused by different quality between the NVIDIA and AMD examples.

Looking at the results for the cuBLAS implementation, we can also see the impact of using a highly optimized library for GPGPU programming. The cuBLAS implementation is faster than using the basic CUDA example, indicating that proper use of libraries can be very beneficial.

It is also important to note that this is a very small test. In order to be able to conclude if CUDA is indeed faster than OpenCL, one would have needed to implement a wide selection of algorithms and test them on several different hardware configurations. Although this test is non conclusive regarding this question, the results seem to support several older investigations, concluding that CUDA is faster than OpenCL\@. One notable example being A Comprehensive Performance Comparison of CUDA and OpenCL\cite{Fang11} by Janbin Fang et al.
% subsection matrix_multiplication_benchmark (end)

\subsection{A quick evaluation of available documentation} % (fold)
\label{sub:a_quick_evaluation_of_available_documentation}

When we where installing CUDA and OpenCL, and implementing our test algorithms, we relied on the online documentation available for the two GPGPU frameworks. Our subjective experience was that finding good documentation for CUDA was a lot easier than for OpenCL\@. In order to investigate this, we made a series of queries for pages related to CUDA and OpenCL on Google, Google scholar and Stackoverflow.com (a popular programming QA site). The results are shown in the following tables (all data from 16. Jan 2014).

\begin{table}[ht]
\centering
    \begin{tabular}{ | l | l |}
    \hline
    \textbf{Query}     & \textbf{No of Stackoverflow.com results}    \\ \hline
    Tagged OpenCL      & 1935                                        \\ \hline
    Tagged CUDA        & 6137                                        \\ \hline
    Open search OpenCL & 5818                                        \\ \hline
    Open search CUDA   & 16174                                       \\ \hline
    \end{tabular}
    \caption{Query results from Stackoverflow}
    \label{fig:stackoverflow-terms-results}
\end{table}

\begin{table}[ht]
\centering
    \begin{tabular}{ | l | l | l |}
    \hline
    \textbf{Query} & \textbf{No of Google results} & \textbf{No of Google Scholar results} \\ \hline
    opencl paralell programming & 322000    & 7480        \\ \hline
    cuda paralell programming   & 558000    & 17100        \\ \hline
    opencl gpgpu                & 558000    & 5230        \\ \hline
    cuda gpgpu                  & 816000    & 13500        \\ \hline
    opencl programming          & 875000    & 8160        \\ \hline
    cuda programming            & 2790000   & 22700        \\ \hline
    \end{tabular}
    \caption{Query results from Google}
    \label{fig:google-terms-results}
\end{table}
% subsection a_quick_evaluation_of_available_documentation (end)
% section a_short_evaluation_of_opencl_and_cuda (end)


\section{A brute force based approach} % (fold)
\label{sub:investigation_of_a_brute_force_approach_based_on_garcia}

\input{investigation_of_a_brute_force_approach_based_on_garcia.tex}

% section investigation_of_a_brute_force_approach_based_on_garcia (end)

\section{Application of k-d trees to the kNN problem} % (fold)
\label{sub:application_of_kd_trees_to_the_knn_problem}

A common strategy when wanting to improve the performance of repeated queries in a large dataset, is to organize the dataset into some data structure suited for fast querying. This strategy trades the additional time required building an data structure, for increased performance on each query. In Section~\ref{sub:investigation_of_a_brute_force_approach_based_on_garcia} we developed an optimized parallel brute force algorithm for performing kNN queries on a large point cloud. In this section we will investigate the possibility of improving on the brute force algorithm by using the k-d tree data structure.

\begin{myrq}
\label{rq:serial-kd-tree}
    It is possible to use a k-d tree to increase the performance of kNN queries, compared to a parallel brute force solution?
\end{myrq}

\begin{myrq}
\label{rq:serial-kd-tree-all-knn}
    It is possible to use a k-d tree to increase the performance of All-kNN queries, compared to a parallel brute force solution?
\end{myrq}

A brief argument for why k-d trees is well suited for kNN query operations is given, then we will present the k-d tree data structure, and show how it can be used for operating on three-dimensional point cloud data. Finally a set of tests are performed on implementations of the k-d tree based algorithms, in order to determine the possible benefits of a parallel k-d tree based algorithm.

\subsection{Why k-d trees?} % (fold)
\label{sub:why_k_d_trees_}
A large part of this thesis is devoted to applying k-d trees to the kNN problem. The reader might ask themselves why this is so. Other possible data structures exist which is optimized for querying in geometrical data. Why choose to investigate k-d trees in particular?

Part of the explanation has to do with the scope and time resources available for the work in this thesis. Performing a full analysis and parallelization of every possible data structure, and their associated query algorithms, would just not be feasible within our time frame. That said, k-d trees is a very attractive data structure for our use case.

\begin{itemize}
    \item k-d trees are easy to understand and implement, leaving more time to throughly investigate parallelization of the algorithms.
    \item k-d trees are a very minimal data structure, and balanced k-d trees are complete binary trees. This makes reducing the amount of additional memory required in addition to the 3-d points a relative simple task. This is important considering the memory bounds on GPUs, and the time penalty associated with moving data from system memory to GPU memory.
    \item k-d trees are well adapted to performing associative queries, where the query is for a point that is not equal to, but close to the query point.
    \item Studies on parallel kNN queries based on k-d trees has been documented in literature with encouraging results\cite{Owens:2007:ASO,Zhou:2008:RKC:1409060.1409079, Brown2010}.
\end{itemize}
% subsection why_k_d_trees_ (end)

\subsection{Building k-d trees for point cloud data} % (fold)
\label{ssub:building_k_d_trees_for_point_cloud_data}

A k-d tree can be thought of as a binary search tree in k dimensions. A binary search tree is constructed such that, for a given node, one child-subtree is consisting of elements smaller than the current node, and the other child-subtree is consisting of elements larger than the current node. The same strategy is applied when constructing a k-d tree, but at each level we are sorting the child-subtree elements according to one selected dimension, called the discriminant for this level. This discriminant is cycled through the different dimensions, as we move down each level in the tree. A formal description of k-d trees is given by Jon Louis Bentley in the paper Multidimensional Binary Search Trees Used for Associative Searching\cite{Bentley:1975:MBS:361002.361007}.

Let us have a look at an example using data for two dimensions. Figure~\ref{fig:kd_tree_2d_plane} shows us a set of points on a two dimensional plane. The lines through each point indicate the split plane formed by the discriminant associated with the different points.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=85mm]{../gfx/kd_tree_illustration_graph.png}
    \caption{A set of points on a plane, with a possible k-d tree indicated.}
    \label{fig:kd_tree_2d_plane}
\end{figure}

The corresponding k-d tree is shown in Figure~\ref{fig:kd_tree_2d}. Note that lower values in each level are placed in the left branches, and higher values are placed in the right branches.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=120mm]{../gfx/kd_tree_illustration_tree.png}
    \caption{Tree representation of the points in Figure~\ref{fig:kd_tree_2d_plane}.}
    \label{fig:kd_tree_2d}
\end{figure}

By extending this example with three fixed dimensions for the spatial dimensions, x, y, and z, we get a k-d tree suitable for storing point cloud data.

It it possible to construct several algorithms for building k-d trees from a set of points, and one simple approach is using a recursive function. Algorithm~\ref{alg:seriel_tree_build} shows pseudocode for such a simple tree building algorithm. In the pseudocode, we have chosen to represent the different dimensions as a natural number. This means that x is represented by 0, y is represented by 1, z is represented by 2 and so on. Given a set of point, $P$, in $k$ space, and a initial split dimension $i$, it constructs a balanced k-d tree.

\begin{algorithm}
\caption{Recursive k-d tree build}
\label{alg:seriel_tree_build}
\begin{algorithmic}
    \Function{Build-KD-Tree}{$P$, $i$}
        \If{$P.length = 0$} \Comment{We have reached the end of a branch}
            \State \textbf{return} NIL
        \Else
            \State $m \gets \text{Median}(P)$

            \State \text{Let $L$ be all elements of $P < m$ in dimension $i$}
            \State \text{Let $H$ be all elements of $P > m$ in dimension $i$}

            \State $i' \gets (i + 1) \bmod k$ \Comment{k = 3 for a three dimensional k-d tree}

            \State $m.left \gets \text{Build-KD-Tree}(L, i')$
            \State $m.right \gets \text{Build-KD-Tree}(H, i')$
        \EndIf
        \State \textbf{return} $m$
    \EndFunction
\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:seriel_tree_build} starts by checking if there is any more points left in $P$. If not, it returns NIL as an end of branch marker. If there still is points left, the algorithm selects the median point, $m$, as the root node. Then it sorts all remaining points into a collection of points lower than the median, $L$, and higher than the median, $H$. The dimension, $i$, is incremented, and the Build-KD-Tree function is called recursively on both collections of points. Finally the root node is returned, so it can be assigned as the child of it's parent node, or be used as a global root node.

It is worth to note that the performance of this k-d tree build algorithm is sensitive to the choice of a median finding algorithm, since we will be querying for the median \BigO{m} times. Choosing to just sorting the collection $P$, and selecting the median from the middle of the sorted collection, will not give optimal results. Fortunately, several \BigO{m} median selecting algorithms exist\cite{Cormen:2001} (Get chapter citation), quickselect, being the choice for our initial implementations. Given a fixed number of dimensions, this gives a algorithm with a time complexity of \BigO{m\ log(m)}\cite{Friedman:1977}.

A final note about Algorithm~\ref{alg:seriel_tree_build}, is that it does not handles points with duplicate values in one dimension. If the algorithm where to be feed with a point collection where all points had the same value for x, it would not be able to handle it, since such a point does not explicitly belong in $L$ or $H$. Several modifications can be made to handle this case. We can choose to place all conflicting median points, except one, in either $L$ or $H$. The problem with this solution, is that we are not guaranteed to get a balance tree. If we where to have a set of points, where all points where tha same, we would get a tree at all, but just one long branch of length n. Another strategy is to try to place the conflicting medians, equally in $L$ and $H$. This way the median we select will be the midmost element in the point collection, retaining the balance in the finished k-d tree. Given that we consider that duplicate median points can be located in both subtrees of a node, this will not affect search operations on the tree, as we will see later.
% subsection building_k_d_trees_for_point_cloud_data (end)

\subsection{Querying the k-d tree}  % (fold)
\label{sub:querying_the_k_d_tree} 

With a k-d tree we can perform efficient searches for the closest point to a given point in \BigO{log(m)} average time\cite{Friedman:1977}. By maintaining a collection of the k closest points during execution of the query, we can even perform kNN searches. An example of a kNN search algorithm is shown in Algorithm~\ref{alg:recursive_knn_kd_tree_search}.

The procedure will take the root of a k-d tree, $r$ and a query point, for which we want to find the k closest points. In addition, it requires a initial dimension, $i$, which should be the same as the initial dimension used when building the tree. It uses this data to manipulate a collection of the k closest points to $q$. This collection is called the k-heap, $K$.

The k-heap is a data structure with some special properties. You can query it for the maximum distance value of the k points stored in it, and it will only store a predetermined number of points. If you try to insert more points than the predetermined number of points, it will discard the highest values, and only keep the k lowest values. This data structure can be easily implemented as a modified max-heap~\cite[Chapter 6]{Cormen:2001}. When the size of the heap is lower than k, it is used in the usual manner, but when the heap is of size k, a slight modification to the insertion operation is made. Instead of adding the new element to the heap, the new element is swapped with the maximum value of the heap, if it is lower than the current maximum value in the k-heap. Then the heap is re-balanced using the standard max-heap balance algorithm. In our code, we assume the k-heap to be filled at the start with k points of either a random sample of points from the k-d tree, or with positive infinity. This way we do not need to check if the heap is filled during the recursive execution of the procedure.

\begin{algorithm}
\caption{Recursive kNN k-d tree search}
\label{alg:recursive_knn_kd_tree_search}
\begin{algorithmic}
    \Procedure{kNN-KD-Tree}{$K, r, q, i$}
        \If{$r =$ NIL} \Comment{We have reached the end of a branch}
            \State \textbf{return}
        \EndIf

        \State $d \gets \text{Distance}(r, q)$
        \State $dx \gets r.x[i] - q.x[i]$

        \If{$d < K.max$} \Comment{Is $r$ closer to $q$ than the current k best points?}
            \State $r.distance \gets d$
            \State \text{Insert}($K, r$)
        \EndIf

        \State $i' \gets (i + 1) \bmod k$ \Comment{k = 3 for a three dimensional k-d tree}

        \If{$dx > 0$}  \Comment{Select $t$ and $o$ so we traverse towards closest point first}
            \State $t \gets r.left$, $o \gets r.right$
        \Else
            \State $t \gets r.right$, $o \gets r.left$
        \EndIf

        \State \text{kNN-KD-Tree} ($K, t, q, i'$)

        \If{$dx^2 < K.max$} \Comment{Can there be closer points in the other subtree?}
            \State \text{kNN-KD-Tree}($K, o, q, i'$)
        \EndIf
    \EndProcedure
\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:recursive_knn_kd_tree_search} starts by checking if we have reached the end of a branch. If not, it calculates the Euclidean distance between the query point, $q$, and the current root point, $r$. Calculating this distance is a costly step, since it usually involves calculating a square root. This can be circumvented when implementing, by relying on using the square of the Euclidean distance as the distance metric, instead of the actual distance. This will not make a difference for the algorithm. The distance, $dx$, between the current root and the query point in dimension $i$ is also calculated.

The algorithm then checks if the current root point is closer to the query point than one of the points in the k-heap. If this is the case, it inserts the current root into the k-heap. The next dimension, $i'$, is calculated, and then the algorithm determines if it should traverse to the right or left child node first. For efficient querying, we want to traverse down the branch that would contain the query point. In other words, if the query point is lower than the current root point in the current dimension, we want to traverse to the left child, and vice versa. The child node that we want to traverse first, is often called the target, and it's corresponding subtree is often called the target subtree. In the algorithm the symbol $t$ is used to represent target. The child and child-subtree that is not chosen for immediate traversal is called other and other-subtree. In the algorithm the symbol $o$ is used to represent other. The ability to prune away the other subtree, given our current best estimates stored in the k-heap and the distance $dx$, is what makes the k-d tree efficient for kNN searches.

After recursively investigating the target subtree, we ask if our estimates in the k-heap is better than the distance $dx$, remembering that the distances stored in the k-heap is squared. If this is the case, we know that there cannot be a closer point in the other subtree, and we can prune it from our search. If not, we have to check the other subtree as well. When the procedure terminated, the k closest points to the query point is stored in the k-heap.
% subsection querying_the_k_d_tree (end)

\subsection{Testing a serial k-d tree based kNN solver} % (fold)
\label{sub:testing_a_serial_k_d_tree_based_knn_solver}

In order to gain some real world insight into the performance characteristics of k-d tree building and querying, a serial implementation of the build and query algorithm was made. These implementations is available in Appendix~\ref{sec:k_d_tree_build} and Appendix~\ref{sec:cuda_k_d_tree_search}. These two implementations where then subjected to several tests, using test setup Y. All tests were performed on a set of randomly generated points 3-d points, with the number of points ranging from $10^5$ to $1.41*10^7$. The result of these test are summed up in the following figures.

Figure~\ref{fig:serial-build} shows the timing results for the recursive k-d tree build algorithm.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=120mm]{../gfx/serial-build.png}
    \caption{Timing results for recursive k-d tree building}
    \label{fig:serial-build}
\end{figure}

We observe that constructing a k-d tree for a large number of points is a costly operation. Given a tree of size $1.41^7$ the algorithm uses nearly $9$ seconds to construct the tree. We also note that the timing results seem to scale linearly in relation to the number of points. This relates nicely to calculated time complexity of the algorithm.

Figure~\ref{fig:serial-query} shows the timing results for querying a k-d tree of a given size. The k-d tree is queried for one point with $k=1$. Since we are interested in investigating the average performance, $10^5$ consecutive queries was timed, and the average value for one query was calculated.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=120mm]{../gfx/serial-query.png}
    \caption{Timing results for mean query time with k equal to one}
    \label{fig:serial-query}
\end{figure}

We see that querying the k-d tree is very fast on average. Querying for one point in a tree of size $1.41^7$ takes about $0.0014$ milliseconds. It has to be taken into account, that a query with $k=1$ will give the best query time, since the time complexity of the query algorithm scales with k. Still, for queries with a low $k$, we should expect good performance. The graph also seems to scale with the logarithm of the number of points, as expected by the time complexity calculation.

In order to try to answer RQ~\ref{rq:serial-kd-tree}, we compare the timing results gained from the fastest brute force algorithm developed in Section~\ref{sub:investigation_of_a_brute_force_approach_based_on_garcia}. Figure~\ref{fig:brute-force-vs-serial-build-query} compare the average time required for building a k-d tree of a given size, and performing a single $k=1$ query, to the time required to compute the same result with the fastest brute force algorithm obtained in Section~\ref{sub:investigation_of_a_brute_force_approach_based_on_garcia}.

\begin{figure}[ht!]
\centering
\includegraphics[width=120mm]{../gfx/brute-force-vs-serial-build-query.png}
\caption{Comparison of mean query time with k equal to one with fast brute force and recursive k-d tree based algorithms}
\label{fig:brute-force-vs-serial-build-query}
\end{figure}

In this comparison, the k-d tree based algorithm does not seem like a good option. When performing just one query, the additional time required to build the k-d tree heavily outweighs the benefit of the improved query time, compared to the brute force solution. This result is to be expected, since we are not really utilizing the benefit of the k-d tree, but it is still an important point that a brute force algorithm can be very efficient for certain use-cases.

Let us finally look at some results more closely related to the use-case given by TSI\@. Figure~\ref{fig:brute-force-vs-serial-build-n-queries} does the same comparison as Figure~\ref{fig:brute-force-vs-serial-build-query}, but instead of comparing the time taken to perform one query, $n$ repeated queries are performed, with $n$ being the size of the k-d tree.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=120mm]{../gfx/brute-force-vs-serial-build-n-queries.png}
    \caption{Comparison of timing of n queries with k equal to one with fast brute force and recursive k-d tree based algorithms}
    \label{fig:brute-force-vs-serial-build-n-queries}
\end{figure}

We observe that in this use-case, the k-d tree based approach have much better results than the brute force based approach. Now the k-d tree only have to be built once, but we benefit from the decreased query time in all $n$ queries. Performing $n$ queries on a point cloud of size $1.41^7$ with the brute force based algorithm takes about $\numprint{9.7e5}$ seconds, or about 11 days. With the recursive k-d based algorithm, the same operation can be calculated in just over a minute. Considering the needs of TSI, it seem that this approach is worth developing further into an parallel algorithm.

Despite these initial positive results, some problems are apparent from our initial tests.

The k-d tree building algorithm is very slow. Given that we want to perform kNN queries on larger point clouds than $1.41^7$, finding an efficient parallelization of this algorithm would be very beneficial. This is not as trivial as it might seem, as tree-based algorithms do not lend themselves very well to trivial parallelization.

When scaling the number of repeated queries from one to $n$ we observed the huge impact a seemingly small change in the time required for performing one query had on the time needed to compute the entire result. A change from several milliseconds to a fraction of a milliseconds might seem trivial, but given enough repeated queries, this was the difference between minutes and days of computation time. Will we be able to keep the query time down when increasing the value of $k$, and moving the computation over to the GPU, which generally has a slower clock cycle than the CPU.

In the next sections we will address these challenges, along with others, and develop a parallel algorithm for performing kNN queries based on k-d trees.
% subsection testing_a_serial_k_d_tree_based_knn_solver (end)
% % section kd_tree_based_effort (end)

\section{Development of a parallel k-d tree build algorithm} % (fold)
\label{sec:development_of_a_parallel_k_d_tree_build_algorithm}

\input{development_of_a_parallel_kd_tree_build_algorithm}
% section development_of_a_parallel_k_d_tree_build_algorithm (end)

\section{Development of a parallel k-d search algorithm} % (fold)
\label{sec:development_of_a_parallel_k_d_search_algorithm}

\input{development_of_a_parallel_kd_search_algorithm}

% section development_of_a_parallel_k_d_search_algorithm (end)

\section{CUDA Optimizations} % (fold)
\label{sec:cuda_optimizations}

Throughout this quest many optimizations have been done, some focusing on the algorithmic aspect, others more on implementation. This section is focusing on different CUDA optimizations and why it is necessary in regard of performance. Some performance considerations, like divergence, have already been mentioned, due to it's direct relation to the different implementations. Other important factors, occupancy, coalescing, loop-unrolling, block and thread load balancing.
% TODO: Add arithmetic operations in list?

Occupancy is a metric, which relates to how many active warps there are on a SM. Earlier we have talked about how thread instructions are executed sequentially, resulting in alternating warps, one warp is paused while the other is executing. The time a stalled warp will use to retrieve data, increases with the number of warps per SM. One should note that high occupancy does not always result in high performance, but low occupancy will always result in an inability to hide latency, which result in bad performance.

The struggle to always have the right amount of occupancy, also relates to dividing CUDA resources. As well as keeping a right amount of warps in a SM, one must also keep every SM in activity. Forcing the algorithm to work over unsynchronizable blocks. The number of blocks, that are optimal to keep in activity, changes with different GPUs. It is therefore important to think of how many blocks and threads that are launched with each kernel. We have solved this issue with methods that, based on different algorithmic parameters, calculates how many threads and blocks are needed for a particular launch.

To coalesce memory access to global memory, is probably one of the most performance increasing optimizations in CUDA, especially in our memory intense application. Global memory that is loaded and stored by threads in a warp, can be coalesced into only one transaction, if the right conditions are met. How a device coalesce memory depends on the compute capability, but some basic properties are common. A warps access will coalesce into onto a number of transactions that equals the number of cache lines needed to service all the threads in the warp. Devices with compute capability $2.x$ will by default cache directly to L1, which has 128-byte lines. Higher capabilities will always cache to L2 cache, that have 32-byte segments~\cite{cuda_c_best_practices_guide}. 

\begin{figure}[ht!]
    \centering
    \includegraphics[width=100mm]{../gfx/memory_coalecing.png}
    \caption{Three different memory transactions, where A and B result in good coalesced and cached transactions, while C shows a stride access pattern with bad coalescing.}
    \label{fig:coalesing_memory}
\end{figure}

If we focus on compute capability 2.x, Figures~\ref{fig:coalesing_memory}, shows have memory are coalesced. Green indicate memory lines that are retrieved, while blue indicate non retrieved lines. The first figure illustrate perfect coalescing, a warp performs a sequential 128-byte transaction that fit perfectly in a 128-byte lines. The second shows a misaligned sequential retrial, resulting in two transactions. The third uses stride access pattern with a offset of $128$ resulting in bad coalescing.

We have tried to maximize coalescing by always using sequential addressing. This kind of addressing can be achieved in many ways. One way, that we have use throughout the code, is based on how data are partitioned and iterated. The generic partitioning algorithm, Algorithm~\ref{alg:general_aspects_dividing}, that we used to expand Garcia's algorithm, shows how this could be done.     


The last optimization keyword we would like to introduce is unrolling. This is a technique we have used on many of our algorithms, like min-reduce, and also in some of our utility functions, like for example to accumulate an array. Unrolling is a standard technique in ordinary high performance serial programming, optimizing pipelining, and is given an extra dimensions on CUDA\@. 

Loop unrolling, is the procedure of rewriting a loop, containing conditional operators, into hard-coded sequential steps. This way, the result of conditional operators may be determined at compile-time, eliminating branching of the control flow. On a CUDA context this is of course the case, but in addition it will minimize divergence.

The idea of loop unrolling can also be applied to warps. This is called warp unrolling, and it can be used if we know we are in a single warp. The results being, that no expensive thread synchronization is needed, since every warp is accessing a unique memory location.

%TODO: Skal denne være med?.
A last note to add is arithmetic operations. Some arithmetic operations are more costly then others, like modulo and divisions. It is therefore time saving to optimize, in computationally heavy algorithms. This is especially the case in the light weighted threads found in CUDA. For instants, one can use a right bit-shift to divide a number by two.

% section cuda_optimizations (end)

\cleardoublepage
